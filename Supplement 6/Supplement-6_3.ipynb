{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Supplement 6: Decision Trees and Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from scipy.stats import mode\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Programming Task: Song popularity prediction using Random Forest\n",
        "The goal of this task is to train a random forest model that predicts the song popularity using the datasets already provided in task 4.3\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read data\n",
        "\n",
        "#TODO\n",
        "train = pd.read_csv(\"train-songs.csv\").to_numpy()\n",
        "test = pd.read_csv(\"test-songs.csv\").to_numpy()\n",
        "\n",
        "train_X = train[:, :-1]\n",
        "train_y = train[:, -1]\n",
        "test_X = test[:, :-1]\n",
        "test_y = test[:, -1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "   i\\. Implement a function that draws a bootstrap sample of size N from the train dataset, where N can be specified by the user.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_bootstrap(train_X,train_y,N):\n",
        "   idx = np.random.randint(len(train_X), size=N)\n",
        "   return train_X[idx, :], train_y[idx]\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "   ii\\. Complete the implementation of the random forest algorithm. For this task you may use the DecisionTreeClassifier from the scikit-learn library. The other parts of the random forest algorithm must be implemented using only Scipy/Numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RandomForest:\n",
        "   def __init__(self,n_trees,max_features,max_samples,min_node_size, max_depth):\n",
        "\n",
        "      #TODO Initialize list containing weak classifiers. Also initialize any other parameter if required.\n",
        "      self.trees = []\n",
        "      self.random_features_of_trees = []\n",
        "      self.n_trees = n_trees\n",
        "      self.max_features = max_features\n",
        "      self.max_samples = max_samples\n",
        "      self.min_node_size = min_node_size\n",
        "      self.max_depth = max_depth\n",
        "\n",
        "\n",
        "\n",
        "   def train(self,train_X,train_y):\n",
        "      #TODO Training each weak classifier\n",
        "      original_feature_count = len(train_X[0])\n",
        "\n",
        "      for i in range(self.n_trees):\n",
        "         clf = DecisionTreeRegressor(min_samples_leaf=self.min_node_size, max_depth=self.max_depth)\n",
        "         train_bs, test_bs = generate_bootstrap(train_X, train_y, self.max_samples)\n",
        "         \n",
        "         random_features = np.random.choice(original_feature_count, size=self.max_features, replace=False)\n",
        "         self.random_features_of_trees.append(random_features)\n",
        "\n",
        "         clf.fit(train_bs[:, random_features], test_bs)\n",
        "         self.trees.append(clf)\n",
        "\n",
        "\n",
        "   \n",
        "   def predict(self,test_X):\n",
        "      #TODO Final predictions are obtained by taking majority-vote (most frequent class) from each weak classifier prediction\n",
        "      y_prediction = 0\n",
        "      \n",
        "      for i, tree_clf in enumerate(self.trees):\n",
        "         features = self.random_features_of_trees[i]\n",
        "\n",
        "         predictions = tree_clf.predict(test_X[:, features])\n",
        "         y_prediction += predictions\n",
        "\n",
        "      y_prediction /= self.n_trees\n",
        "      y_prediction[y_prediction>0.5] = 1\n",
        "      y_prediction[y_prediction <=0.5] = 0\n",
        "      return y_prediction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "iii\\. Train the model for the dataset from train-songs.csv using the parameters given below.\n",
        "| Parameter| Value|\n",
        "|----------|------|\n",
        "Number of trees|100|\n",
        "Maximum features per tree|2|\n",
        "Bootstrap sample size|20000|\n",
        "Minimum node size|1|\n",
        "Maximum tree depth|10|\n",
        "\n",
        "\n",
        "Note: The bootstrap sample size is the same as train dataset size in this task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: Run this cell without any changes. The model will train if the implementation of subtask (ii) is correct.\n",
        "\n",
        "random_forest_model = RandomForest(n_trees=100, max_samples=20000,max_depth=10,min_node_size=1, max_features=2 )\n",
        "\n",
        "random_forest_model.train(train_X, train_y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "   iv\\. Calculate the accuracy of the model using the test dataset and compare your results with the\n",
        "RandomForestClassifier from the scikit-learn library using the following parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction accuracy of Random Forest:  0.8\n"
          ]
        }
      ],
      "source": [
        "# TODO Run predict for test data and calculate accuracy\n",
        "predictions = random_forest_model.predict(test_X)\n",
        "\n",
        "accuracy = 1 - np.mean( np.abs(predictions - test_y) ) \n",
        "print(\"Prediction accuracy of Random Forest: \", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction accuracy of Sklearn Random Forest:  0.8\n"
          ]
        }
      ],
      "source": [
        "# TODO: Train and predict using scikit-learn library\n",
        "clf = RandomForestClassifier(n_estimators=100, max_samples=20000, max_depth=10, min_samples_leaf=1, max_features=2)\n",
        "clf.fit(train_X, train_y)\n",
        "clf_pred = clf.predict(test_X)\n",
        "\n",
        "accuracy_sk = 1 - np.mean( np.abs(clf_pred - test_y) ) \n",
        "print(\"Prediction accuracy of Sklearn Random Forest: \", accuracy)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "pytorch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:41:22) [MSC v.1929 64 bit (AMD64)]"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "5f72f1a0d6306d26c3b23fbcb6a984e7dfdecbc3132d92c0f69a7837c178b288"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
