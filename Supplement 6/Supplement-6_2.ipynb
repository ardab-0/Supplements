{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplement 6: Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree,export_graphviz\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Programming Task: Regression Trees\n",
    "The datasets in files train-reg-tree.csv and test-reg-tree.csv contain samples from a synthetic dataset for training a Regression Tree. The dataset consists of 3 columns: the first two\n",
    "columns, denoted as x1 and x2, represent the input features for each data sample, and the last\n",
    "column represents target value denoted by y. There are 200 samples in the train-reg-tree.csv\n",
    "and 100 samples in the test-reg-tree.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO-1 Read data\n",
    "\n",
    "train =  pd.read_csv(\"train-songs.csv\")\n",
    "# test = ...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a node M containing N M samples, the node impurity can be expressed by the node\n",
    "sample variance:\n",
    "$$V_M = \\frac{1}{N_M}\\sum_{i=1}^{N_M}(Y_i - \\overline{Y}_{\\!M})^2,$$\n",
    "where $Y_i$ is the target of the sample $i$ and $Y_M$ is the mean target of all samples in the node. Similar\n",
    "to equation 6.2, the goodness-of-split is given by:\n",
    "$$\\Delta V =V_P - \\biggl(\\frac{N_L}{N_P}\\cdot V_L + \\frac{N_R}{N_P}\\cdot V_R\\biggl)$$\n",
    "where $V_P$ , $V_L$ , $V_R$ are the variances of the parent node, left node and right node respectively."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   i\\. Complete the missing code in the implementation of the Regression tree.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def split(parent_region, feature_index, threshold):\n",
    "    # Splits data into left and right using threshold condition\n",
    "\n",
    "    region_left = parent_region[parent_region[:,feature_index] <=threshold]\n",
    "    region_right = parent_region[parent_region[:,feature_index] >threshold]\n",
    "    return region_left, region_right\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def variance(dataset_y):\n",
    "    # dataset_y is a numpy array from the dataset containing only target(y) column\n",
    "    \n",
    "    #TODO-2 Implement variance\n",
    "\n",
    "\n",
    "    #return var\n",
    "\n",
    "\n",
    "def goodness_of_fit(parent_y, l_child_y, r_child_y):\n",
    "    # All three inputs are numpy arrays from the dataset containing only the target(y) column\n",
    "    \n",
    "    # TODO-3 Implement goodness-of-fit\n",
    "\n",
    "\n",
    "\n",
    "    #return reduction\n",
    "\n",
    "\n",
    "\n",
    "def find_split_function(dataset):\n",
    "    # Dataset -> numpy array with all columns of train including target(y) column\n",
    "\n",
    "    # TODO-4 Find the best split function by looping through all possible split functions and selecting the split function with the maximum goodness_of_fit\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "    # return the best split function as dictionary containing: feature_index, threshold,dataset_left, dataset_right,variance, goodness_of_fit\n",
    "\n",
    "    #return best_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, feature_index, threshold, left, right,variance):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "        self.threshold = threshold\n",
    "        self.feature_index = feature_index\n",
    "\n",
    "        self.variance = variance\n",
    "        \n",
    "        self.value = None # Non-leaf nodes don't store values.\n",
    "\n",
    "    def info_string(self):\n",
    "        '''Generates string containing information about node. Used for tree visualization'''\n",
    "        split_function= f\"X[{self.feature_index}]<= {self.threshold:.3f}\"\n",
    "        mse = f\"var = {self.variance:.3f}\"\n",
    "        info_string = f\"{split_function}\\n{mse}\"\n",
    "        return info_string\n",
    "        \n",
    "\n",
    "\n",
    "class LeafNode:\n",
    "    def __init__(self,dataset_y):\n",
    "        \n",
    "        # For regression the leaf node stores the mean of all samples at that node as its value.\n",
    "        self.value = np.mean(dataset_y)\n",
    "    \n",
    "    def info_string(self):\n",
    "        '''Generates string containing information about node. Used for tree visualization'''\n",
    "        info_string = f\"value = {self.value:.3f}\"\n",
    "        return info_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTree():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2): \n",
    "             \n",
    "        # initialize the root of the tree \n",
    "        self.root = None\n",
    "        \n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, depth=1):\n",
    "\n",
    "        # This function will be called recursively to build subsequent deeper nodes. \n",
    "        # The function returns a node.\n",
    "        \n",
    "\n",
    "        num_samples = dataset.shape[0]\n",
    "        # Check stopping conditions\n",
    "        if num_samples>=self.min_samples_split and depth<=self.max_depth:\n",
    "            # find best split function\n",
    "            best_split = find_split_function(dataset)\n",
    "\n",
    "            # check if goodness is positive, else move to leaf node directly\n",
    "            if best_split[\"goodness_of_fit\"]>0:\n",
    "                # Build left tree\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], depth+1)\n",
    "                # Build right tree\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], depth+1)\n",
    "                # return decision node\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],left_subtree, right_subtree, best_split['variance'])\n",
    "        \n",
    "\n",
    "        # return leaf node\n",
    "        return LeafNode(dataset_y=dataset[:,-1])\n",
    "    \n",
    "\n",
    "            \n",
    "    \n",
    "    def train(self, dataset):\n",
    "        self.root = self.build_tree(dataset)\n",
    "        \n",
    "    def node_predict(self, x_sample, node):\n",
    "        \n",
    "        # TODO-5 Return the value if node is leaf, else check the threshold condition \n",
    "        # and call the same function (node_predict) with left or right node \n",
    "        # depending on the threshold condition. This is also a recursive function like build_tree.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        \n",
    "        predictions = [self.node_predict(x_sample, self.root) for x_sample in X]\n",
    "        return predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ii\\. Train the above regression tree using the train dataset and obtain the mean square error (MSE) for the model predictions on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Run this cell without any changes. The model will train if the implementation of subtask (i) is correct.\n",
    "# Make sure you complete all 5 TODO for above.\n",
    "\n",
    "regressor = RegressionTree(min_samples_split=3,max_depth=4)\n",
    "regressor.train(train)\n",
    "y = regressor.predict(test[:,:2])\n",
    "\n",
    "mse_our = np.mean((test[:,2] -y)**2)\n",
    "print('Our regression-tree MSE:',mse_our)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   iii\\. Compare your results using the model trained using the DecisionTreeRegressor class from the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO-6 Train and predict using scikit-learn library\n",
    "# clf = DecisionTreeRegressor(min_samples_split=3, max_depth=4)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL: Tree Visualization\n",
    "Please install graphviz library.\n",
    "If you are using anaconda, run:\n",
    "\n",
    "conda install -c conda-forge python-graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph, Source\n",
    "\n",
    "\n",
    "def print_tree(current_node,graph,parent_node_name='root'):\n",
    "    ''' function to print the tree '''\n",
    "    graph.node(parent_node_name,current_node.info_string())\n",
    "    \n",
    "    if current_node.value is None:        \n",
    "    \n",
    "        left_node_name = parent_node_name+'L'\n",
    "        right_node_name = parent_node_name+'R'\n",
    "\n",
    "        graph = print_tree(current_node.left, graph, left_node_name)\n",
    "        graph = print_tree(current_node.right, graph, right_node_name)\n",
    "\n",
    "        graph.edge(parent_node_name,left_node_name,len='1.00')\n",
    "        graph.edge(parent_node_name,right_node_name,len='1.00')\n",
    "\n",
    "    return graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree_graph = Digraph(filename='reg-tree')\n",
    "reg_tree_graph.attr('node', shape='box')\n",
    "reg_tree_graph.attr('edge',fixedsize='true')\n",
    "\n",
    "print_tree(regressor.root, reg_tree_graph).view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(clf, out_file=None,rounded=True, filled=True)  \n",
    "\n",
    "graph = Source(dot_data,filename='sklearn-reg-tree')\n",
    "graph.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f72f1a0d6306d26c3b23fbcb6a984e7dfdecbc3132d92c0f69a7837c178b288"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
