{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Supplement 4: Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pandas as pd\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Programming Task: K-Nearest Neighbor\n",
        "The datasets in files __train-knn.csv__ and __test-knn.csv__ contain samples from a synthetic dataset for training a K-Nearest Neighbor classifier.\n",
        "The dataset consists of 7 columns: the first six columns, denoted as x1, x2, ..., x6 represent\n",
        " the input features for each data sample, and the last column represents the class label given by 0 or 1.\n",
        "There are 200 samples in the __train-knn.csv__ and 100 samples in the __test-knn.csv__}.\n",
        "\n",
        "i\\. Implement the K-Nearest Neighbor classification algorithm using NumPy and SciPy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "def knn_scipy(train_X, train_y, predict_X, n_neighbors=3):\n",
        "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    neigh.fit(train_X, train_y)\n",
        "    return neigh.predict(predict_X)\n",
        "\n",
        "\n",
        "class kNearestNeighbor():\n",
        "    def __init__(self, k):\n",
        "        self.__k = k\n",
        "        self.__mMax = 1e8\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # store references to the labeled training data\n",
        "        self.__X = X\n",
        "        self.__y = y\n",
        "        self.__m = len(X)\n",
        "        self.__classes = np.sort(list(set(self.__y))).astype(np.int)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # |x-y|^2 = (x - y)^T (x - y) = - 2 * x^T y + x^T x + y^T y\n",
        "        # runtime efficient as for-loops are avoided, but runs out of memory\n",
        "        # pretty fast for large training and test sets;\n",
        "        # process only m test samples at a time\n",
        "\n",
        "        m = int(self.__mMax / self.__m)\n",
        "        numRuns = math.ceil(len(X) / m)\n",
        "\n",
        "        z = np.zeros(0)\n",
        "        for i in range(numRuns):\n",
        "            Xs = X[i * m:(i + 1) * m]\n",
        "            d1 = np.square(Xs).sum(axis=1)\n",
        "            d2 = np.square(self.__X).sum(axis=1)\n",
        "            D = np.dot(Xs, self.__X.T)\n",
        "            D *= -2\n",
        "            D += d1.reshape(-1, 1)\n",
        "            D += d2\n",
        "\n",
        "            ind = np.argsort(D, axis=1)[:, 0:self.__k]\n",
        "            del D\n",
        "\n",
        "            cl = self.__y[ind]\n",
        "            del ind\n",
        "\n",
        "            counts = np.empty((0, len(Xs)))\n",
        "            for c in self.__classes:\n",
        "                counts = np.vstack((counts, (cl == c).sum(axis=1)))\n",
        "\n",
        "            ind = np.argmax(counts, axis=0)\n",
        "            del counts\n",
        "\n",
        "            z = np.append(z, ind)\n",
        "\n",
        "        # mapping to class labels\n",
        "        Z = np.zeros(len(X))\n",
        "        for i in range(len(self.__classes)):\n",
        "            Z[z == i] = self.__classes[i]\n",
        "\n",
        "        return Z\n",
        "\n",
        "def knn(train_X, train_y, predict_X, n_neighbors=3):\n",
        "    knn = kNearestNeighbor(n_neighbors)\n",
        "    knn.fit(train_X, train_y)\n",
        "    return knn.predict(predict_X)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ii\\. Perform cross-validation (with 5 folds) on the train dataset __train-knn.csv__ to determine a suitable value of K.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy in fold:  0.7\n",
            "Accuracy in fold:  0.725\n",
            "Accuracy in fold:  0.725\n",
            "Accuracy in fold:  0.775\n",
            "Accuracy in fold:  0.675\n",
            "Average accuracy for k = 1: 0.72\n",
            "Accuracy in fold:  0.725\n",
            "Accuracy in fold:  0.8\n",
            "Accuracy in fold:  0.775\n",
            "Accuracy in fold:  0.825\n",
            "Accuracy in fold:  0.775\n",
            "Average accuracy for k = 3: 0.78\n",
            "Accuracy in fold:  0.8\n",
            "Accuracy in fold:  0.85\n",
            "Accuracy in fold:  0.725\n",
            "Accuracy in fold:  0.85\n",
            "Accuracy in fold:  0.75\n",
            "Average accuracy for k = 5: 0.795\n",
            "Accuracy in fold:  0.825\n",
            "Accuracy in fold:  0.8\n",
            "Accuracy in fold:  0.75\n",
            "Accuracy in fold:  0.8\n",
            "Accuracy in fold:  0.725\n",
            "Average accuracy for k = 7: 0.78\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardab\\AppData\\Local\\Temp\\ipykernel_7904\\510274192.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.__classes = np.sort(list(set(self.__y))).astype(np.int)\n"
          ]
        }
      ],
      "source": [
        "dataset_pd = pd.read_csv(\"train-knn.csv\")\n",
        "dataset_X = dataset_pd[[\"x1\",\"x2\",\"x3\",\"x4\",\"x5\",\"x6\"]].to_numpy() \n",
        "dataset_y = dataset_pd[\"class\"].to_numpy() \n",
        "\n",
        "def cross_validation(X, y, k=5):\n",
        "    N = len(X)\n",
        "    fold_len = int(N / k)\n",
        "    folds = []\n",
        "    indices = np.arange(0, N, fold_len)[1:]\n",
        "    X_parts = np.split(X, indices)\n",
        "    y_parts = np.split(y, indices)\n",
        "\n",
        "    train_folds = []\n",
        "    test_folds = []\n",
        "\n",
        "    \n",
        "    for i in range(k):\n",
        "        X_train_fold = np.concatenate(np.delete(X_parts, i, axis=0))\n",
        "        y_train_fold = np.concatenate(np.delete(y_parts, i, axis=0))\n",
        "\n",
        "        X_test_fold = X_parts[i]\n",
        "        y_test_fold = y_parts[i]\n",
        "        train_folds.append((X_train_fold, y_train_fold))\n",
        "        test_folds.append((X_test_fold, y_test_fold))\n",
        "    return zip(train_folds, test_folds)\n",
        "\n",
        "\n",
        "ks = [1, 3, 5, 7]\n",
        "\n",
        "for k in ks:\n",
        "    accuracies = []\n",
        "    for (train_X, train_y), (test_X, test_y) in cross_validation(dataset_X, dataset_y):\n",
        "        predictions = knn(train_X, train_y, test_X, k)\n",
        "        accuracy = 1 - np.sum(np.abs(predictions - test_y)) / len(predictions)\n",
        "        print(\"Accuracy in fold: \", accuracy)\n",
        "        accuracies.append(accuracy)\n",
        "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "    print(\"Average accuracy for k = {}: {}\".format(k, avg_accuracy))\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "iii\\. Using the optimal value of k from the cross-validation, obtain the accuracy of your model on the test dataset __test-knn.csv__.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for k = 5 in test dataset : 0.78\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ardab\\AppData\\Local\\Temp\\ipykernel_7904\\510274192.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.__classes = np.sort(list(set(self.__y))).astype(np.int)\n"
          ]
        }
      ],
      "source": [
        "test_dataset_pd = pd.read_csv(\"test-knn.csv\")\n",
        "test_dataset_X = test_dataset_pd[[\"x1\",\"x2\",\"x3\",\"x4\",\"x5\",\"x6\"]].to_numpy() \n",
        "test_dataset_y = test_dataset_pd[\"class\"].to_numpy() \n",
        "\n",
        "k = 5\n",
        "predictions = knn(dataset_X, dataset_y, test_dataset_X, k)\n",
        "accuracy = 1 - np.sum(np.abs(predictions - test_dataset_y)) / len(predictions)\n",
        "print(\"Accuracy for k = {} in test dataset : {}\".format(k, avg_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "iv\\. Compare your result with the KNeighborsClassifier model from the scikit-learn library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for k = 5 in test dataset using scikit-learn library's KNeighborsClassifier: 0.78\n"
          ]
        }
      ],
      "source": [
        "\n",
        "predictions = knn_scipy(dataset_X, dataset_y, test_dataset_X, k)\n",
        "accuracy = 1 - np.sum(np.abs(predictions - test_dataset_y)) / len(predictions)\n",
        "print(\"Accuracy for k = {} in test dataset using scikit-learn library's KNeighborsClassifier: {}\".format(k, avg_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "v\\. How do the bias and variance of each model vary as K increases?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As K increases variance of the model increases, whereas bias decreases."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 ('python_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "adbe77a04a76d932345bb7bdb8702cea8988e308e9e4d2da8550c44417464104"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
